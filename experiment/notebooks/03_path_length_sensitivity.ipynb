{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decda771",
   "metadata": {},
   "source": [
    "# 03_path_length_sensitivity.ipynb\n",
    "\n",
    "**Claim under test:**  \n",
    "Pathwise regret scales ~ linearly with P_T at fixed λ and G.\n",
    "\n",
    "**Grid file:** `grids/03_path_length_sensitivity.yaml`\n",
    "\n",
    "**Baseline & conventions**\n",
    "- Use the STAR schema built by `experiment/utils/duck-db-loader.py`.\n",
    "- Slice results by `(grid_id, seed)` using `analytics.v_run_summary`.\n",
    "- Keep plots identical across notebooks; only the *dial* under test changes.\n",
    "- Reference path-length/regret-decomposition companion analysis for context. :contentReference[oaicite:0]{index=0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce4688",
   "metadata": {},
   "source": [
    "## 0) Imports & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e275d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# go up one level\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# project paths (edit if your repo layout differs)\n",
    "REPO = Path(\".\").resolve()\n",
    "RESULTS_GLOB = \"results_parquet/03_path_length_sensitivity/events/grid_id=*/seed=*/*.parquet\"  # corrected pattern\n",
    "DB_PATH = REPO/\"artifacts\"/\"star.duckdb\"\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GRID_FILE = REPO/\"grids/03_path_length_sensitivity.yaml\"     # this notebook’s grid\n",
    "STAGING_TABLE = \"staging.events\"   # keep default from loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea29652",
   "metadata": {},
   "source": [
    "## 1) Build/load the STAR schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24735927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.duck_db_loader import load_star_schema\n",
    "\n",
    "con = load_star_schema(\n",
    "    input_path=str(RESULTS_GLOB),\n",
    "    db_path=str(DB_PATH),\n",
    "    staging_table=STAGING_TABLE,\n",
    "    run_ddl=True,\n",
    "    create_events_view=True,\n",
    ")\n",
    "\n",
    "# sanity: counts\n",
    "display(con.execute(\"\"\"\n",
    "SELECT 'dim_run' t, COUNT(*) c FROM analytics.dim_run\n",
    "UNION ALL SELECT 'fact_event', COUNT(*) FROM analytics.fact_event\n",
    "UNION ALL SELECT 'dim_event_type', COUNT(*) FROM analytics.dim_event_type\n",
    "\"\"\").df())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c12f41",
   "metadata": {},
   "source": [
    "## 2) Snapshot config & runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4415fd0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# show the grid dictionary if kept in YAML (optional)\n",
    "try:\n",
    "    import yaml, textwrap\n",
    "    cfg = yaml.safe_load(Path(GRID_FILE).read_text())\n",
    "    print(\"grid file:\", GRID_FILE)\n",
    "    print(json.dumps(cfg.get(\"matrix\", {}), indent=2))\n",
    "except Exception as e:\n",
    "    print(\"Note: could not parse YAML grid:\", e)\n",
    "\n",
    "runs = con.execute(\"\"\"\n",
    "SELECT *\n",
    "FROM analytics.v_run_summary\n",
    "ORDER BY grid_id, seed\n",
    "\"\"\").df()\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7497a6fc",
   "metadata": {},
   "source": [
    "## 3) Standard query helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74757f9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def last_event_frame(con, grid_id:str, seed:int):\n",
    "    return con.execute(\"\"\"\n",
    "    WITH last AS (\n",
    "      SELECT MAX(event_id) AS last_id\n",
    "      FROM analytics.fact_event fe\n",
    "      WHERE fe.grid_id = ? AND fe.seed = ?\n",
    "    )\n",
    "    SELECT fe.*\n",
    "    FROM analytics.fact_event fe\n",
    "    CROSS JOIN last l\n",
    "    WHERE fe.event_id = l.last_id AND fe.grid_id = ? AND fe.seed = ?\n",
    "    \"\"\", [grid_id, seed, grid_id, seed]).df()\n",
    "\n",
    "def trace_frame(con, grid_id:str, seed:int, cols:tuple[str,...]):\n",
    "    col_list = \", \".join(cols)\n",
    "    return con.execute(f\"\"\"\n",
    "    SELECT event_id, {col_list}\n",
    "    FROM analytics.fact_event fe\n",
    "    WHERE fe.grid_id = ? AND fe.seed = ?\n",
    "    ORDER BY event_id\n",
    "    \"\"\", [grid_id, seed]).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbeaff2",
   "metadata": {},
   "source": [
    "## 4) Plots (standardized)\n",
    "Keep styling consistent across notebooks for visual comparability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf08b884",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_traces(df, ycols, title):\n",
    "    for y in ycols:\n",
    "        plt.figure()\n",
    "        plt.plot(df[\"event_id\"], df[y], label=y)\n",
    "        plt.xlabel(\"event_id\"); plt.ylabel(y); plt.title(f\"{title}: {y}\")\n",
    "        plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad919e3",
   "metadata": {},
   "source": [
    "## 5) Notebook-specific check: claim, dial, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_CLAIM = \"Pathwise regret scales ~ linearly with P_T at fixed λ and G.\"\n",
    "print(\"Claim under test:\", NOTEBOOK_CLAIM)\n",
    "\n",
    "# choose a (grid_id, seed) to visualize (edit if multiple)\n",
    "if not runs.empty:\n",
    "    gid, seed = runs.loc[0, [\"grid_id\",\"seed\"]]\n",
    "    print(\"Example run:\", gid, seed)\n",
    "\n",
    "    # universal traces\n",
    "    df = trace_frame(con, gid, int(seed), (\n",
    "        \"cum_regret\", \"regret_static_term\", \"regret_path_term\",\n",
    "        \"P_T_true\", \"ST_running\", \"g_norm\", \"eta_t\"\n",
    "    ))\n",
    "    plot_traces(df, [\"cum_regret\",\"regret_static_term\",\"regret_path_term\"], \"Regret decomposition\")\n",
    "    plot_traces(df, [\"P_T_true\",\"ST_running\"], \"Path & energy\")\n",
    "    plot_traces(df, [\"g_norm\",\"eta_t\"], \"Grad norm & step size\")\n",
    "\n",
    "    # end-of-run snapshot\n",
    "    tail = last_event_frame(con, gid, int(seed))\n",
    "    display(tail[[\"cum_regret\",\"cum_regret_with_noise\",\"P_T_true\",\"ST_running\",\"rho_spent\",\"m_used\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cfa17b",
   "metadata": {},
   "source": [
    "## 6) One-page “claim check” (export)\n",
    "Emits a compact JSON summary to artifacts/ for CI diffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747aae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT = REPO/\"artifacts\"/(Path(\"03_path_length_sensitivity.ipynb\").stem + \"_claim_check.json\")\n",
    "ARTIFACT.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "summary = con.execute(\"\"\"\n",
    "SELECT\n",
    "  dr.grid_id, dr.seed,\n",
    "  MAX(fe.cum_regret) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_cum_regret,\n",
    "  MAX(fe.cum_regret_with_noise) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_cum_regret_with_noise,\n",
    "  MAX(fe.P_T_true) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_P_T_true,\n",
    "  MAX(fe.ST_running) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_ST_running,\n",
    "  MAX(fe.rho_spent) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_rho_spent,\n",
    "  MAX(fe.m_used) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_m_used\n",
    "FROM analytics.fact_event fe\n",
    "JOIN analytics.dim_run dr USING (run_key)\n",
    "GROUP BY dr.grid_id, dr.seed\n",
    "ORDER BY dr.grid_id, dr.seed\n",
    "\"\"\").df().to_dict(orient=\"records\")\n",
    "\n",
    "ARTIFACT.write_text(json.dumps({\n",
    "    \"notebook\": \"03_path_length_sensitivity.ipynb\",\n",
    "    \"claim\": NOTEBOOK_CLAIM,\n",
    "    \"grid_file\": str(GRID_FILE),\n",
    "    \"summary\": summary\n",
    "}, indent=2))\n",
    "print(\"Wrote:\", ARTIFACT)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
