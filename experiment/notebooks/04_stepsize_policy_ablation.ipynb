{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff18dad8",
   "metadata": {},
   "source": [
    "# 04_stepsize_policy_ablation.ipynb\n",
    "\n",
    "**Claim under test:**  \n",
    "Changing stepsize policy alters stability and regret without changing geometry.\n",
    "\n",
    "**Grid file:** `grids/04_stepsize_ablation.yaml`\n",
    "\n",
    "**Baseline & conventions**\n",
    "- Use the STAR schema built by `experiment/utils/duck-db-loader.py`.\n",
    "- Slice results by `(grid_id, seed)` using `analytics.v_run_summary`.\n",
    "- Keep plots identical across notebooks; only the *dial* under test changes.\n",
    "- Reference path-length/regret-decomposition companion analysis for context. :contentReference[oaicite:0]{index=0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2556a",
   "metadata": {},
   "source": [
    "## 0) Imports & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed51c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# project paths (edit if your repo layout differs)\n",
    "REPO = Path(\".\").resolve()\n",
    "RESULTS_GLOB = \"results/**/events*.parquet\"  # or CSVs\n",
    "DB_PATH = REPO/\"artifacts\"/\"star.duckdb\"\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GRID_FILE = REPO/\"grids/04_stepsize_ablation.yaml\"     # this notebook’s grid\n",
    "STAGING_TABLE = \"staging.events\"   # keep default from loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b64b8",
   "metadata": {},
   "source": [
    "## 1) Build/load the STAR schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39982901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment.utils.duck_db_loader import load_star_schema\n",
    "\n",
    "con = load_star_schema(\n",
    "    input_path=str(RESULTS_GLOB),\n",
    "    db_path=str(DB_PATH),\n",
    "    staging_table=STAGING_TABLE,\n",
    "    run_ddl=True,\n",
    "    create_events_view=True,\n",
    ")\n",
    "\n",
    "# sanity: counts\n",
    "display(con.execute(\"\"\"\n",
    "SELECT 'dim_run' t, COUNT(*) c FROM analytics.dim_run\n",
    "UNION ALL SELECT 'fact_event', COUNT(*) FROM analytics.fact_event\n",
    "UNION ALL SELECT 'dim_event_type', COUNT(*) FROM analytics.dim_event_type\n",
    "\"\"\").df())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a0078c",
   "metadata": {},
   "source": [
    "## 2) Snapshot config & runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38521ea6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# show the grid dictionary if kept in YAML (optional)\n",
    "try:\n",
    "    import yaml, textwrap\n",
    "    cfg = yaml.safe_load(Path(GRID_FILE).read_text())\n",
    "    print(\"grid file:\", GRID_FILE)\n",
    "    print(json.dumps(cfg.get(\"matrix\", {}), indent=2))\n",
    "except Exception as e:\n",
    "    print(\"Note: could not parse YAML grid:\", e)\n",
    "\n",
    "runs = con.execute(\"\"\"\n",
    "SELECT *\n",
    "FROM analytics.v_run_summary\n",
    "ORDER BY grid_id, seed\n",
    "\"\"\").df()\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ddeaa",
   "metadata": {},
   "source": [
    "## 3) Standard query helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5324b27e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def last_event_frame(con, grid_id:str, seed:int):\n",
    "    return con.execute(\"\"\"\n",
    "    WITH last AS (\n",
    "      SELECT run_key, MAX(event_id) AS last_id\n",
    "      FROM analytics.fact_event fe\n",
    "      JOIN analytics.dim_run dr USING (run_key)\n",
    "      WHERE dr.grid_id = ? AND dr.seed = ?\n",
    "      GROUP BY run_key\n",
    "    )\n",
    "    SELECT fe.*\n",
    "    FROM analytics.fact_event fe\n",
    "    JOIN analytics.dim_run dr USING (run_key)\n",
    "    JOIN last l USING (run_key)\n",
    "    WHERE fe.event_id = l.last_id\n",
    "    \"\"\", [grid_id, seed]).df()\n",
    "\n",
    "def trace_frame(con, grid_id:str, seed:int, cols:tuple[str,...]):\n",
    "    col_list = \", \".join(cols)\n",
    "    return con.execute(f\"\"\"\n",
    "    SELECT event_id, {col_list}\n",
    "    FROM analytics.fact_event fe\n",
    "    JOIN analytics.dim_run dr USING (run_key)\n",
    "    WHERE dr.grid_id = ? AND dr.seed = ?\n",
    "    ORDER BY event_id\n",
    "    \"\"\", [grid_id, seed]).df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd71f93",
   "metadata": {},
   "source": [
    "## 4) Plots (standardized)\n",
    "Keep styling consistent across notebooks for visual comparability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50112287",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_traces(df, ycols, title):\n",
    "    for y in ycols:\n",
    "        plt.figure()\n",
    "        plt.plot(df[\"event_id\"], df[y], label=y)\n",
    "        plt.xlabel(\"event_id\"); plt.ylabel(y); plt.title(f\"{title}: {y}\")\n",
    "        plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5b755a",
   "metadata": {},
   "source": [
    "## 5) Notebook-specific check: claim, dial, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_CLAIM = \"Changing stepsize policy alters stability and regret without changing geometry.\"\n",
    "print(\"Claim under test:\", NOTEBOOK_CLAIM)\n",
    "\n",
    "# choose a (grid_id, seed) to visualize (edit if multiple)\n",
    "if not runs.empty:\n",
    "    gid, seed = runs.loc[0, [\"grid_id\",\"seed\"]]\n",
    "    print(\"Example run:\", gid, seed)\n",
    "\n",
    "    # universal traces\n",
    "    df = trace_frame(con, gid, int(seed), (\n",
    "        \"cum_regret\", \"regret_static_term\", \"regret_path_term\",\n",
    "        \"P_T_true\", \"ST_running\", \"g_norm\", \"eta_t\"\n",
    "    ))\n",
    "    plot_traces(df, [\"cum_regret\",\"regret_static_term\",\"regret_path_term\"], \"Regret decomposition\")\n",
    "    plot_traces(df, [\"P_T_true\",\"ST_running\"], \"Path & energy\")\n",
    "    plot_traces(df, [\"g_norm\",\"eta_t\"], \"Grad norm & step size\")\n",
    "\n",
    "    # end-of-run snapshot\n",
    "    tail = last_event_frame(con, gid, int(seed))\n",
    "    display(tail[[\"cum_regret\",\"cum_regret_with_noise\",\"P_T_true\",\"ST_running\",\"rho_spent\",\"m_used\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c12c24",
   "metadata": {},
   "source": [
    "## 6) One-page “claim check” (export)\n",
    "Emits a compact JSON summary to artifacts/ for CI diffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc15248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT = REPO/\"artifacts\"/(Path(\"04_stepsize_policy_ablation.ipynb\").stem + \"_claim_check.json\")\n",
    "ARTIFACT.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "summary = con.execute(\"\"\"\n",
    "SELECT\n",
    "  dr.grid_id, dr.seed,\n",
    "  MAX(fe.cum_regret) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_cum_regret,\n",
    "  MAX(fe.cum_regret_with_noise) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_cum_regret_with_noise,\n",
    "  MAX(fe.P_T_true) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_P_T_true,\n",
    "  MAX(fe.ST_running) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_ST_running,\n",
    "  MAX(fe.rho_spent) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_rho_spent,\n",
    "  MAX(fe.m_used) FILTER (WHERE fe.event_id = (SELECT MAX(event_id) FROM analytics.fact_event WHERE run_key = fe.run_key)) AS final_m_used\n",
    "FROM analytics.fact_event fe\n",
    "JOIN analytics.dim_run dr USING (run_key)\n",
    "GROUP BY dr.grid_id, dr.seed\n",
    "ORDER BY dr.grid_id, dr.seed\n",
    "\"\"\").df().to_dict(orient=\"records\")\n",
    "\n",
    "ARTIFACT.write_text(json.dumps({\n",
    "    \"notebook\": \"04_stepsize_policy_ablation.ipynb\",\n",
    "    \"claim\": NOTEBOOK_CLAIM,\n",
    "    \"grid_file\": str(GRID_FILE),\n",
    "    \"summary\": summary\n",
    "}, indent=2))\n",
    "print(\"Wrote:\", ARTIFACT)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
