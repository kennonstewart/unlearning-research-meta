{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ee635c",
   "metadata": {},
   "source": [
    "# Experiment A: Bound Adherence Under Nonstationary Conditions\n",
    "*Question: does empirical average regret stay within the $\\gamma$-regret bounds?*\n",
    "\n",
    "### Experiment Design\n",
    "Grid search over the streams (stationary, slow, abrupt, periodic), lambda levels, and two deletion ratio regimes.\n",
    "\n",
    "Use a static comparator and calibrated learning rate schedule.\n",
    "Set gamma per-theory at calibration and fix the total horizon (ie. $T=50000$).\n",
    "\n",
    "### Primary Analysis\n",
    "For each of the experimental cells, evaluate the final $R_{T}/T$ to see whether the guarantee was met.\n",
    "Multiple seeds per cell in order to make some kind of causal analysis on the results.\n",
    "\n",
    "### Success Criteria\n",
    "95% of the cells meet their guarantees then I would call that a success. Which cells experience more successes than others? Can I make a heatmap that shows the regret results per cell?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39829cf",
   "metadata": {},
   "source": [
    "## Import Statements and Versioning\n",
    "\n",
    "This uses pretty standard library imports, but the torch requirement can stress the memory limits of a host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75752267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global seed\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Set the random seed for reproducibility.\n",
    "    \n",
    "    Args:\n",
    "        seed (int): The seed value to set for random number generation.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82eb8f",
   "metadata": {},
   "source": [
    "# Config and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6adc2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = \"experiment_a_test\"\n",
    "REGIME = \"stationary\"\n",
    "REPLICATE = 1\n",
    "T = 1000\n",
    "SEED = 42\n",
    "LOSS_NAME = \"logistic\"\n",
    "MODEL_NAME = \"memorypair\"\n",
    "LBFGS_MEM = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d0d1b",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "calibration_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add code path for imports\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from config import Config\n",
    "from runner import ExperimentRunner\n",
    "\n",
    "from agents.grid_runner import load_grid, generate_combinations, create_grid_id, run_parameter_combination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_fix",
   "metadata": {},
   "source": [
    "# Test the d_max Fix\n",
    "\n",
    "This section demonstrates that the d_max None value error has been fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 grid cells\n",
      "['zcdp']\n",
      " 1. gamma_1.0-split_0.3_q0.95_k0_zcdp_eps1.0 → {'gamma_bar': 1.0, 'gamma_split': 0.3, 'accountant': 'zcdp', 'rho_total': 1.0, 'delta_total': '1e-5', 'stream_len': 50000, 'drift_regime': 'stationary', 'delete_ratio': 0.05, 'comparator': 'static', 'enable_oracle': False, 'oracle_window_W': 512, 'oracle_steps': 10, 'oracle_stride': None, 'oracle_tol': '1e-6', 'oracle_warmstart': True, 'path_length_norm': 'L2', 'lambda_reg': '1e-4', 'm_max': 1000, 'd_max': 1000, 'lbfgs_pair_gate_m_t': '1e-3', 'lbfgs_spectrum_clip': ['1e-6', '1e3'], 'ema_beta': 0.9, 'lambda_est_beta': 0.1, 'lambda_est_bounds': ['1e-8', '1e4'], 'bootstrap_iters': 500, 'quantile': 0.95, 'dataset': 'synthetic', 'loss_name': 'logistic'}\n",
      " 2. gamma_1.0-split_0.3_q0.95_k0_zcdp_eps1.0 → {'gamma_bar': 1.0, 'gamma_split': 0.3, 'accountant': 'zcdp', 'rho_total': 1.0, 'delta_total': '1e-5', 'stream_len': 50000, 'drift_regime': 'stationary', 'delete_ratio': 0.05, 'comparator': 'static', 'enable_oracle': False, 'oracle_window_W': 512, 'oracle_steps': 10, 'oracle_stride': None, 'oracle_tol': '1e-6', 'oracle_warmstart': True, 'path_length_norm': 'L2', 'lambda_reg': '1e-3', 'm_max': 1000, 'd_max': 1000, 'lbfgs_pair_gate_m_t': '1e-3', 'lbfgs_spectrum_clip': ['1e-6', '1e3'], 'ema_beta': 0.9, 'lambda_est_beta': 0.1, 'lambda_est_bounds': ['1e-8', '1e4'], 'bootstrap_iters': 500, 'quantile': 0.95, 'dataset': 'synthetic', 'loss_name': 'logistic'}\n",
      " 3. gamma_1.0-split_0.3_q0.95_k0_zcdp_eps1.0 → {'gamma_bar': 1.0, 'gamma_split': 0.3, 'accountant': 'zcdp', 'rho_total': 1.0, 'delta_total': '1e-5', 'stream_len': 50000, 'drift_regime': 'stationary', 'delete_ratio': 0.2, 'comparator': 'static', 'enable_oracle': False, 'oracle_window_W': 512, 'oracle_steps': 10, 'oracle_stride': None, 'oracle_tol': '1e-6', 'oracle_warmstart': True, 'path_length_norm': 'L2', 'lambda_reg': '1e-4', 'm_max': 1000, 'd_max': 1000, 'lbfgs_pair_gate_m_t': '1e-3', 'lbfgs_spectrum_clip': ['1e-6', '1e3'], 'ema_beta': 0.9, 'lambda_est_beta': 0.1, 'lambda_est_bounds': ['1e-8', '1e4'], 'bootstrap_iters': 500, 'quantile': 0.95, 'dataset': 'synthetic', 'loss_name': 'logistic'}\n",
      " 4. gamma_1.0-split_0.3_q0.95_k0_zcdp_eps1.0 → {'gamma_bar': 1.0, 'gamma_split': 0.3, 'accountant': 'zcdp', 'rho_total': 1.0, 'delta_total': '1e-5', 'stream_len': 50000, 'drift_regime': 'stationary', 'delete_ratio': 0.2, 'comparator': 'static', 'enable_oracle': False, 'oracle_window_W': 512, 'oracle_steps': 10, 'oracle_stride': None, 'oracle_tol': '1e-6', 'oracle_warmstart': True, 'path_length_norm': 'L2', 'lambda_reg': '1e-3', 'm_max': 1000, 'd_max': 1000, 'lbfgs_pair_gate_m_t': '1e-3', 'lbfgs_spectrum_clip': ['1e-6', '1e3'], 'ema_beta': 0.9, 'lambda_est_beta': 0.1, 'lambda_est_bounds': ['1e-8', '1e4'], 'bootstrap_iters': 500, 'quantile': 0.95, 'dataset': 'synthetic', 'loss_name': 'logistic'}\n",
      " 5. gamma_1.0-split_0.3_q0.95_k0_zcdp_eps1.0 → {'gamma_bar': 1.0, 'gamma_split': 0.3, 'accountant': 'zcdp', 'rho_total': 1.0, 'delta_total': '1e-5', 'stream_len': 50000, 'drift_regime': 'slow', 'delete_ratio': 0.05, 'comparator': 'static', 'enable_oracle': False, 'oracle_window_W': 512, 'oracle_steps': 10, 'oracle_stride': None, 'oracle_tol': '1e-6', 'oracle_warmstart': True, 'path_length_norm': 'L2', 'lambda_reg': '1e-4', 'm_max': 1000, 'd_max': 1000, 'lbfgs_pair_gate_m_t': '1e-3', 'lbfgs_spectrum_clip': ['1e-6', '1e3'], 'ema_beta': 0.9, 'lambda_est_beta': 0.1, 'lambda_est_bounds': ['1e-8', '1e4'], 'bootstrap_iters': 500, 'quantile': 0.95, 'dataset': 'synthetic', 'loss_name': 'logistic'}\n",
      "\n",
      "=== Running cell 1/16: gamma_1.0-split_0.3_q0.95_k0_zcdp_eps1.0 ===\n",
      "\n",
      "=== Running grid cell: gamma_1.0-split_0.3_q0.95_k0_zcdp_eps1.0 ===\n",
      "Parameters: {'gamma_bar': 1.0, 'gamma_split': 0.3, 'accountant': 'zcdp', 'rho_total': 1.0, 'delta_total': '1e-5', 'stream_len': 50000, 'drift_regime': 'stationary', 'delete_ratio': 0.05, 'comparator': 'static', 'enable_oracle': False, 'oracle_window_W': 512, 'oracle_steps': 10, 'oracle_stride': None, 'oracle_tol': '1e-6', 'oracle_warmstart': True, 'path_length_norm': 'L2', 'lambda_reg': '1e-4', 'm_max': 1000, 'd_max': 1000, 'lbfgs_pair_gate_m_t': '1e-3', 'lbfgs_spectrum_clip': ['1e-6', '1e3'], 'ema_beta': 0.9, 'lambda_est_beta': 0.1, 'lambda_est_bounds': ['1e-8', '1e4'], 'bootstrap_iters': 500, 'quantile': 0.95, 'dataset': 'synthetic', 'loss_name': 'logistic'}\n",
      "Output granularity: event\n",
      "Warning: numeric-like strings detected; consider fixing grids.yaml: {'path_length_norm': 'L2', 'out_dir': 'results/grid_2025_08_15/sweep/gamma_1.0-split_0.3_q0.95_k0_zcdp_eps1.0'}\n",
      "[Bootstrap] Collecting 500 steps to estimate G, D, c, C...\n",
      "[Bootstrap] Finalizing calibration...\n",
      "[Calibrator] G_hat = 29.7968 (quantile 0.95)\n",
      "[Calibrator] D_hat = 0.4789 (clamped by D_cap = 10.0)\n",
      "[Calibrator] c_hat = 1.0000, C_hat = 1.0000\n",
      "[MemoryPair] Calibration complete. N* = 2263, transitioning to LEARNING phase.\n",
      "[MemoryPair] Odometer will be finalized after warmup completes.\n",
      "[SensCalib] Collecting 50 sensitivity samples...\n",
      "[Warmup] Running 1763 warmup inserts to reach N*=2263...\n",
      "[MemoryPair] Reached N* = 2263 inserts. Ready to predict, transitioning to INTERLEAVING phase.\n",
      "[Finalize] Finalizing odometer...\n",
      "[ZCDPOdometer] Warning: Even m=1 exceeds constraints\n",
      "[ZCDPOdometer] Required σ for m=1: 210.6955\n",
      "[ZCDPOdometer] Regret bound: 68.2059 > γ=0.7000\n",
      "[ZCDPOdometer] Joint optimization selected m=1, σ=210.6955\n",
      "[ZCDPOdometer] Final regret bound: 68.2059\n",
      "[ZCDPOdometer] Joint optimization: m = 1, σ = 210.6955\n",
      "[ZCDPOdometer] L = 29.7968, D = 0.4789\n",
      "[ZCDPOdometer] Sensitivity bound = 297.9684\n",
      "[ZCDPOdometer] Using theoretical sensitivity bound L/λ\n",
      "[Finalize] Finalizing odometer...\n",
      "[ZCDPOdometer] Joint optimization selected m=2, σ=297.9684\n",
      "[ZCDPOdometer] Final regret bound: 0.4489\n",
      "[ZCDPOdometer] Joint optimization: m = 2, σ = 297.9684\n",
      "[ZCDPOdometer] L = 29.7968, D = 0.4789\n",
      "[ZCDPOdometer] Sensitivity bound = 297.9684\n",
      "[ZCDPOdometer] Using theoretical sensitivity bound L/λ\n",
      "[Workload] Starting interleaving phase (up to 997687 events)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(combos):\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Running cell \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(combos)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcreate_grid_id(params)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     csvs = \u001b[43mrun_parameter_combination\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSEEDS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_out_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBASE_OUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_granularity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOUTPUT_GRANULARITY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparallel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# bump if your runner supports safe parallelism in-notebook\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     all_csv.extend(csvs)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Persist a manifest like the CLI does (handy for analysis notebooks)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/experiments/deletion_capacity/agents/grid_runner.py:219\u001b[39m, in \u001b[36mrun_parameter_combination\u001b[39m\u001b[34m(params, seeds, base_out_dir, output_granularity, parallel)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m parallel == \u001b[32m1\u001b[39m:\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# Sequential execution\u001b[39;00m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         result = \u001b[43mrun_single_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_out_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_granularity\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    223\u001b[39m             csv_paths.append(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/experiments/deletion_capacity/agents/grid_runner.py:176\u001b[39m, in \u001b[36mrun_single_experiment\u001b[39m\u001b[34m(params, seed, base_out_dir, output_granularity)\u001b[39m\n\u001b[32m    173\u001b[39m runner = ExperimentRunner(cfg)\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# Run for this specific seed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_single_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# The runner should create a CSV file directly in the out_dir\u001b[39;00m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# Look for files matching the expected pattern\u001b[39;00m\n\u001b[32m    180\u001b[39m csv_pattern = os.path.join(run_out_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m*.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/experiments/deletion_capacity/runner.py:136\u001b[39m, in \u001b[36mExperimentRunner.run_single_seed\u001b[39m\u001b[34m(self, seed)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single_seed\u001b[39m(\u001b[38;5;28mself\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    135\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run experiment for a single seed and return CSV path.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_one_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.csv_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/experiments/deletion_capacity/runner.py:178\u001b[39m, in \u001b[36mExperimentRunner.run_one_seed\u001b[39m\u001b[34m(self, seed)\u001b[39m\n\u001b[32m    175\u001b[39m finalize_accountant_phase(model, \u001b[38;5;28mself\u001b[39m.cfg)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# Phase 5: Workload\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m state, events_used = \u001b[43mworkload_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_events_left\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# Save results and create summary\u001b[39;00m\n\u001b[32m    181\u001b[39m csv_path = \u001b[38;5;28mself\u001b[39m._save_seed_results(seed, logger, state, model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/experiments/deletion_capacity/phases.py:399\u001b[39m, in \u001b[36mworkload_phase\u001b[39m\u001b[34m(model, gen, cfg, logger, state, max_events_left)\u001b[39m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    396\u001b[39m     \u001b[38;5;66;03m# Decide: insert or delete based on ratio\u001b[39;00m\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m k_inserts < cfg.delete_ratio:\n\u001b[32m    398\u001b[39m         \u001b[38;5;66;03m# Insert\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m         pred, grad = \u001b[43mget_pred_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m         gnorm = np.linalg.norm(grad)\n\u001b[32m    402\u001b[39m         acc_val = abs_error(pred, state.current_y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/experiments/deletion_capacity/phases.py:51\u001b[39m, in \u001b[36mget_pred_and_grad\u001b[39m\u001b[34m(model, x, y, is_calibration)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33minsert\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m):\n\u001b[32m     53\u001b[39m         \u001b[38;5;66;03m# Fallback if insert doesn't return grad or is in wrong phase\u001b[39;00m\n\u001b[32m     54\u001b[39m         pred = model.insert(x, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/experiments/deletion_capacity/../../code/memory_pair/src/memory_pair.py:525\u001b[39m, in \u001b[36mMemoryPair.insert\u001b[39m\u001b[34m(self, x, y, return_grad, log_to_odometer)\u001b[39m\n\u001b[32m    522\u001b[39m \u001b[38;5;28mself\u001b[39m._update_step_size()\n\u001b[32m    524\u001b[39m \u001b[38;5;66;03m# 5. Compute L-BFGS direction with step-size\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m direction = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlbfgs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_old\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalibrator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcalibrator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[38;5;28mself\u001b[39m.d_norm = \u001b[38;5;28mfloat\u001b[39m(np.linalg.norm(direction))\n\u001b[32m    528\u001b[39m \u001b[38;5;66;03m# Apply trust region clipping if needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/experiments/deletion_capacity/../../code/memory_pair/src/lbfgs.py:101\u001b[39m, in \u001b[36mLimitedMemoryBFGS.direction\u001b[39m\u001b[34m(self, grad, calibrator)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s, y, a, r_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.S, \u001b[38;5;28mself\u001b[39m.Y, \u001b[38;5;28mreversed\u001b[39m(alpha), \u001b[38;5;28mreversed\u001b[39m(rho)):\n\u001b[32m    100\u001b[39m     b = r_i * (y @ r)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     r = r + s * (a - b)\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# Apply final bounds to direction to prevent extreme values\u001b[39;00m\n\u001b[32m    104\u001b[39m direction = -r\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import yaml\n",
    "\n",
    "GRID_FILE = \"grids_exptA.yaml\"\n",
    "BASE_OUT = \"results/grid_2025_08_15\"   # date-stamp it\n",
    "OUTPUT_GRANULARITY = \"event\"           # Experiment A wants per-event for the money plot\n",
    "SEEDS = list(range(5))                 # match your CLI default\n",
    "\n",
    "# Load grid config from YAML\n",
    "with open(GRID_FILE, \"r\") as f:\n",
    "    grid_config = yaml.safe_load(f)\n",
    "\n",
    "# Initialize ExperimentRunner with YAML config\n",
    "runner = ExperimentRunner(config=grid_config)\n",
    "\n",
    "combos = generate_combinations(grid_config)\n",
    "\n",
    "print(f\"{len(combos)} grid cells\")\n",
    "print(sorted(set(c['accountant'] for c in combos)))\n",
    "\n",
    "# (Optional) dry-run preview\n",
    "for i, p in enumerate(combos[:5]):\n",
    "    print(f\"{i+1:2d}. {create_grid_id(p)} → {p}\")\n",
    "\n",
    "# Make output dirs\n",
    "os.makedirs(os.path.join(BASE_OUT, \"sweep\"), exist_ok=True)\n",
    "\n",
    "# Run the sweep using ExperimentRunner\n",
    "all_csv = []\n",
    "for i, params in enumerate(combos):\n",
    "    print(f\"\\n=== Running cell {i+1}/{len(combos)}: {create_grid_id(params)} ===\")\n",
    "    csvs = runner.run_parameter_combination(\n",
    "        params=params,\n",
    "        seeds=SEEDS,\n",
    "        base_out_dir=BASE_OUT,\n",
    "        output_granularity=OUTPUT_GRANULARITY,\n",
    "        parallel=1,           # bump if your runner supports safe parallelism in-notebook\n",
    "    )\n",
    "    all_csv.extend(csvs)\n",
    "\n",
    "# Persist a manifest like the CLI does (handy for analysis notebooks)\n",
    "manifest = { create_grid_id(p): p for p in combos }\n",
    "with open(os.path.join(BASE_OUT, \"sweep\", \"manifest.json\"), \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(\"\\nDone. CSVs:\", len(all_csv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d5cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
