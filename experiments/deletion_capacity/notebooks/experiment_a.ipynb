{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ee635c",
   "metadata": {},
   "source": [
    "# Experiment A: Bound Adherence Under Nonstationary Conditions\n",
    "*Question: does empirical average regret stay within the $\\gamma$-regret bounds?*\n",
    "\n",
    "### Experiment Design\n",
    "Grid search over the streams (stationary, slow, abrupt, periodic), lambda levels, and two deletion ratio regimes.\n",
    "\n",
    "Use a static comparator and calibrated learning rate schedule.\n",
    "Set gamma per-theory at calibration and fix the total horizon (ie. $T=50000$).\n",
    "\n",
    "### Primary Analysis\n",
    "For each of the experimental cells, evaluate the final $R_{T}/T$ to see whether the guarantee was met.\n",
    "Multiple seeds per cell in order to make some kind of causal analysis on the results.\n",
    "\n",
    "### Success Criteria\n",
    "95% of the cells meet their guarantees then I would call that a success. Which cells experience more successes than others? Can I make a heatmap that shows the regret results per cell?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39829cf",
   "metadata": {},
   "source": [
    "## Import Statements and Versioning\n",
    "\n",
    "This uses pretty standard library imports, but the torch requirement can stress the memory limits of a host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75752267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global seed\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Set the random seed for reproducibility.\n",
    "    \n",
    "    Args:\n",
    "        seed (int): The seed value to set for random number generation.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82eb8f",
   "metadata": {},
   "source": [
    "# Config and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = \"experiment_a_test\"\n",
    "REGIME = \"stationary\"\n",
    "REPLICATE = 1\n",
    "T = 1000\n",
    "SEED = 42\n",
    "LOSS_NAME = \"logistic\"\n",
    "MODEL_NAME = \"memorypair\"\n",
    "LBFGS_MEM = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d0d1b",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calibration_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add code path for imports\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), \"..\", \"code\"))\n",
    "\n",
    "from config import Config\n",
    "from runner import ExperimentRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_fix",
   "metadata": {},
   "source": [
    "# Test the d_max Fix\n",
    "\n",
    "This section demonstrates that the d_max None value error has been fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_d_max_fix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters that previously caused the error\n",
    "test_params = {\n",
    "    'gamma_bar': 1.0,\n",
    "    'gamma_split': 0.3,\n",
    "    'accountant': 'zcdp',\n",
    "    'rho_total': 1.0,\n",
    "    'delta_total': 1e-05,\n",
    "    'max_events': 1000,  # Reduced for testing\n",
    "    'delete_ratio': 0.05,\n",
    "    'comparator': 'static',\n",
    "    'd_max': None,  # This was causing the error\n",
    "    'bootstrap_iters': 50,\n",
    "    'quantile': 0.95,\n",
    "    'dataset': 'synthetic',\n",
    "    'seeds': 2\n",
    "}\n",
    "\n",
    "# Create configuration\n",
    "set_seed(SEED)\n",
    "cfg = Config.from_cli_args(**test_params)\n",
    "print(f\"Configuration created successfully!\")\n",
    "print(f\"d_max value: {cfg.d_max} (should be inf, not None)\")\n",
    "\n",
    "# Create and test runner\n",
    "runner = ExperimentRunner(cfg)\n",
    "print(f\"ExperimentRunner created successfully!\")\n",
    "\n",
    "# Run one seed to verify the fix\n",
    "print(f\"Running experiment for seed {SEED}...\")\n",
    "result = runner.run_one_seed(seed=SEED)\n",
    "print(f\"âœ… Experiment completed successfully! No d_max comparison error.\")\n",
    "print(f\"Result type: {type(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The d_max None value comparison error has been fixed. The configuration now properly handles None values by converting them to the default value (float('inf')) for non-Optional fields."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
