{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ee635c",
   "metadata": {},
   "source": [
    "# Experiment A: Bound Adherence Under Nonstationary Conditions\n",
    "*Question: does empirical average regret stay within the $\\gamma$-regret bounds?*\n",
    "\n",
    "### Experiment Design\n",
    "Grid search over the streams (stationary, slow, abrupt, periodic), lambda levels, and two deletion ratio regimes.\n",
    "\n",
    "Use a static comparator and calibrated learning rate schedule.\n",
    "Set gamma per-theory at calibration and fix the total horizon (ie. $T=50000$).\n",
    "\n",
    "### Primary Analysis\n",
    "For each of the experimental cells, evaluate the final $R_{T}/T$ to see whether the guarantee was met.\n",
    "Multiple seeds per cell in order to make some kind of causal analysis on the results.\n",
    "\n",
    "### Success Criteria\n",
    "95% of the cells meet their guarantees then I would call that a success. Which cells experience more successes than others? Can I make a heatmap that shows the regret results per cell?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39829cf",
   "metadata": {},
   "source": [
    "## Import Statements and Versioning\n",
    "\n",
    "This uses pretty standard library imports, but the torch requirement can stress the memory limits of a host."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75752267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global seed\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Set the random seed for reproducibility.\n",
    "    \n",
    "    Args:\n",
    "        seed (int): The seed value to set for random number generation.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82eb8f",
   "metadata": {},
   "source": [
    "# Config and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = \"experiment_a_test\"\n",
    "REGIME = \"stationary\"\n",
    "REPLICATE = 1\n",
    "T = 1000\n",
    "SEED = 42\n",
    "LOSS_NAME = \"logistic\"\n",
    "MODEL_NAME = \"memorypair\"\n",
    "LBFGS_MEM = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d0d1b",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calibration_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add code path for imports\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from config import Config\n",
    "from runner import ExperimentRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_fix",
   "metadata": {},
   "source": [
    "# Test the d_max Fix\n",
    "\n",
    "This section demonstrates that the d_max None value error has been fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_d_max_fix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration created successfully!\n",
      "d_max value: inf (should be inf, not None)\n",
      "ExperimentRunner created successfully!\n",
      "Running experiment for seed 42...\n",
      "[Bootstrap] Collecting 50 steps to estimate G, D, c, C...\n",
      "[Bootstrap] Finalizing calibration...\n",
      "[Calibrator] G_hat = 30.5823 (quantile 0.95)\n",
      "[Calibrator] D_hat = 0.1771 (clamped by D_cap = 10.0)\n",
      "[Calibrator] c_hat = 1.0000, C_hat = 1.0000\n",
      "[MemoryPair] Calibration complete. N* = 327, transitioning to LEARNING phase.\n",
      "[MemoryPair] Odometer will be finalized after warmup completes.\n",
      "[SensCalib] Collecting 50 sensitivity samples...\n",
      "[Warmup] Running 277 warmup inserts to reach N*=327...\n",
      "[MemoryPair] Reached N* = 327 inserts. Ready to predict, transitioning to INTERLEAVING phase.\n",
      "[Finalize] Finalizing odometer...\n",
      "[ZCDPOdometer] Warning: Even m=1 exceeds constraints\n",
      "[ZCDPOdometer] Required σ for m=1: 216.2493\n",
      "[ZCDPOdometer] Regret bound: 495.3428 > γ=0.7000\n",
      "[ZCDPOdometer] Joint optimization selected m=1, σ=216.2493\n",
      "[ZCDPOdometer] Final regret bound: 495.3428\n",
      "[ZCDPOdometer] Joint optimization: m = 1, σ = 216.2493\n",
      "[ZCDPOdometer] L = 30.5823, D = 0.1771\n",
      "[ZCDPOdometer] Sensitivity bound = 305.8227\n",
      "[ZCDPOdometer] Using theoretical sensitivity bound L/λ\n",
      "[Finalize] Finalizing odometer...\n",
      "[ZCDPOdometer] Warning: Even m=1 exceeds constraints\n",
      "[ZCDPOdometer] Required σ for m=1: 216.2493\n",
      "[ZCDPOdometer] Regret bound: 162.0504 > γ=0.7000\n",
      "[ZCDPOdometer] Joint optimization selected m=1, σ=216.2493\n",
      "[ZCDPOdometer] Final regret bound: 162.0504\n",
      "[ZCDPOdometer] Joint optimization: m = 1, σ = 216.2493\n",
      "[ZCDPOdometer] L = 30.5823, D = 0.1771\n",
      "[ZCDPOdometer] Sensitivity bound = 305.8227\n",
      "[ZCDPOdometer] Using theoretical sensitivity bound L/λ\n",
      "[Workload] Starting interleaving phase (up to 623 events)...\n",
      "✅ Experiment completed successfully! No d_max comparison error.\n",
      "Result type: <class 'runner.SeedResult'>\n"
     ]
    }
   ],
   "source": [
    "# Test parameters that previously caused the error\n",
    "test_params = {\n",
    "    'gamma_bar': 1.0,\n",
    "    'gamma_split': 0.3,\n",
    "    'accountant': 'zcdp',\n",
    "    'rho_total': 1.0,\n",
    "    'delta_total': 1e-05,\n",
    "    'max_events': 1000,  # Reduced for testing\n",
    "    'delete_ratio': 0.05,\n",
    "    'comparator': 'static',\n",
    "    'd_max': None,  # This was causing the error\n",
    "    'bootstrap_iters': 50,\n",
    "    'quantile': 0.95,\n",
    "    'dataset': 'synthetic',\n",
    "    'seeds': 2\n",
    "}\n",
    "\n",
    "# Create configuration\n",
    "set_seed(SEED)\n",
    "cfg = Config.from_cli_args(**test_params)\n",
    "print(f\"Configuration created successfully!\")\n",
    "print(f\"d_max value: {cfg.d_max} (should be inf, not None)\")\n",
    "\n",
    "# Create and test runner\n",
    "runner = ExperimentRunner(cfg)\n",
    "print(f\"ExperimentRunner created successfully!\")\n",
    "\n",
    "# Run one seed to verify the fix\n",
    "print(f\"Running experiment for seed {SEED}...\")\n",
    "result = runner.run_one_seed(seed=SEED)\n",
    "print(f\"✅ Experiment completed successfully! No d_max comparison error.\")\n",
    "print(f\"Result type: {type(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Targets & accounting ===\n",
    "gamma_bar:        [1.0]            # target average-regret level γ\n",
    "gamma_split:      [0.3]            # % of γ reserved for unlearning/noise vs learner\n",
    "accountant:       [\"zcdp\"]         # or add \"legacy\" to compare accountants in A/B runs\n",
    "rho_total:        [1.0]            # used when accountant=zcdp\n",
    "delta_total:      [\"1e-5\"]         # (for reporting / conversions)\n",
    "\n",
    "# === Stream & schedule ===\n",
    "stream_len:       [50000]          # total events T per run\n",
    "drift_regime:     [\"stationary\", \"slow\", \"abrupt\", \"periodic\"]  # your generator should read this\n",
    "delete_ratio:     [0.05, 0.2]      # deletes per insert (light/heavy)\n",
    "# Optional: use a string-coded schedule if your runner supports it\n",
    "# delete_schedule: [\"poisson:lambda=0.005\", \"burst:k=5,B=500\"]\n",
    "\n",
    "# === Comparator & oracle (A focuses on static, add dynamic if desired) ===\n",
    "comparator:       [\"static\"]       # add \"dynamic\" if you want both in one sweep\n",
    "enable_oracle:    [false]          # true only if your dynamic comparator needs an oracle path\n",
    "oracle_window_W:  [512]\n",
    "oracle_steps:     [10]\n",
    "oracle_stride:    [null]\n",
    "oracle_tol:       [\"1e-6\"]\n",
    "oracle_warmstart: [true]\n",
    "path_length_norm: [\"L2\"]\n",
    "\n",
    "# === Optimization / model stability ===\n",
    "lambda_reg:             [\"1e-4\", \"1e-3\"]  # weak → strong convexity sweep\n",
    "m_max:                  [1000]            # hard cap on deletes\n",
    "d_max:                  [null]\n",
    "lbfgs_pair_gate_m_t:    [\"1e-3\"]\n",
    "lbfgs_spectrum_clip:    [[\"1e-6\", \"1e3\"]] # [c_hat_min, C_hat_max]\n",
    "ema_beta:               [0.9]\n",
    "lambda_est_beta:        [0.1]\n",
    "lambda_est_bounds:      [[\"1e-8\", \"1e4\"]]\n",
    "\n",
    "# === Calibration ===\n",
    "bootstrap_iters:  [500]\n",
    "quantile:         [0.95]\n",
    "\n",
    "# === Dataset / generator (match your loaders) ===\n",
    "dataset:          [\"linear\"]       # swap/extend: [\"linear\",\"covtype\",\"cifar10\",\"mnist\"]\n",
    "loss_name:        [\"logistic\"]     # or \"squared\" (must match what your runner expects)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
