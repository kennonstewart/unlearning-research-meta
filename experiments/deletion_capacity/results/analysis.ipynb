{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a78bd9e",
   "metadata": {},
   "source": [
    "## Visualizing Results of the Deletion Capacity Experiment\n",
    "\n",
    "These are the results of the deletion capacity experiment. \n",
    "\n",
    "At a high level, we're seeing very conservative regret bounds for the Memory Pair. This means that we're requiring large sample complexity in return for a very low deletion capacity.\n",
    "\n",
    "It's also worth noting that our sample complexity (bar for a good learner) increases as the data wiggles more. When the Lipschitz constant and upper-bound on the Hessian are high, the sample complexity jumps and the amount of noise injected to the model becomes destabilizingly high.\n",
    "\n",
    "Goals:\n",
    "- Analyze the simulation results from the experiment runs and visualize the cumulative regret\n",
    "- Focus on $\\widehat{G}$ such that we can see its impact on the downstream stability of the learner\n",
    "- Investigate alternative methods of privacy accounting. Can we get tigheter regret bounds such that we don't inject so much noise into the parameter estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb8ae3",
   "metadata": {},
   "source": [
    "\n",
    "### Page-Wide Questions\n",
    "- The formulas for sample complexity and deletion capacity look very similar (ie. use the $GD$ term). Why is this the case, and what does this suggest about the relationship between these two formulas? If I were to divide sample complexity by deletion capacity, it would almost look like something like a harmonic mean.\n",
    "- I wonder how $\\widehat{D}$ is being estimated. It looks like a lot of seeds are capping it at 10, which is a worst-case scenario. Is there something that can reduce this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e2ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b4621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_record = \"\"\"\n",
    "C_hat,D_hat,G_hat,N_star_theory,P_T_est,S_scalar,acc,c_hat,capacity_remaining,delta_step_theory,delta_total,eps_spent,eps_step_theory,eta_t,event,event_id,event_type,lambda_est,m_theory,op,regret,rho_step,sample_id,segment_id,sens_delete,sigma_step,sigma_step_theory,x_norm\n",
    ",,,,,,4.511492515380755,,inf,,,0.0,,,0,0,calibrate,,,calibrate,0.0,,linear_053060,0,,,,5.282049655914307\n",
    ",,,,,,0.6477066254256968,,inf,,,0.0,,,1,1,calibrate,,,calibrate,0.0,,linear_902593,0,,,,3.2045962810516357\n",
    ",,,,,,3.6940734626420304,,inf,,,0.0,,,2,2,calibrate,,,calibrate,0.0,,linear_086976,0,,,,3.4850804805755615\n",
    ",,,,,,1.3768957923705547,,inf,,,0.0,,,3,3,calibrate,,,calibrate,0.0,,linear_828659,0,,,,4.006361961364746\n",
    ",,,,,,0.9326645666037168,,inf,,,0.0,,,4,4,calibrate,,,calibrate,0.0,,linear_958359,0,,,,3.5934643745422363\n",
    "\"\"\"\n",
    "\n",
    "columns = [\n",
    "    \"C_hat\", \"D_hat\", \"G_hat\", \"N_star_theory\", \"P_T_est\", \"S_scalar\", \"acc\", \"c_hat\", \"capacity_remaining\", \"delta_step_theory\", \"delta_total\", \"eps_spent\", \"eps_step_theory\", \"eta_t\", \"event\", \"event_id\", \"event_type\", \"lambda_est\", \"m_theory\", \"op\", \"regret\", \"rho_step\", \"sample_id\", \"segment_id\", \"sens_delete\", \"sigma_step\", \"sigma_step_theory\", \"x_norm\"\n",
    "]\n",
    "\n",
    "file_path = \"/workspaces/unlearning-research-meta/experiments/deletion_capacity/results/grid_2025_01_01/sweep/split_0.3-0.7_q0.90_k1_legacy_eps1.0/seed_001_synthetic_memorypair.csv\"\n",
    "\n",
    "data = pd.read_csv(file_path, names=columns, header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "588bb1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['calibrate', 'warmup', 'insert', 'delete'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n",
    "\n",
    "# create a dictionary of dataframes by event type\n",
    "event_dfs = {event: data[data[\"event_type\"] == event] for event in data[\"event_type\"].unique()}\n",
    "event_dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a03fee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for calibrate:\n",
      "       C_hat  D_hat  G_hat  N_star_theory  P_T_est  S_scalar         acc  \\\n",
      "count    0.0    0.0    0.0            0.0      0.0       0.0  500.000000   \n",
      "mean     NaN    NaN    NaN            NaN      NaN       NaN    1.709943   \n",
      "std      NaN    NaN    NaN            NaN      NaN       NaN    1.281029   \n",
      "min      NaN    NaN    NaN            NaN      NaN       NaN    0.005286   \n",
      "25%      NaN    NaN    NaN            NaN      NaN       NaN    0.708226   \n",
      "50%      NaN    NaN    NaN            NaN      NaN       NaN    1.502960   \n",
      "75%      NaN    NaN    NaN            NaN      NaN       NaN    2.417920   \n",
      "max      NaN    NaN    NaN            NaN      NaN       NaN    7.185795   \n",
      "\n",
      "       c_hat  capacity_remaining  delta_step_theory  ...    event_id  \\\n",
      "count    0.0               500.0                0.0  ...  500.000000   \n",
      "mean     NaN                 inf                NaN  ...  249.500000   \n",
      "std      NaN                 NaN                NaN  ...  144.481833   \n",
      "min      NaN                 inf                NaN  ...    0.000000   \n",
      "25%      NaN                 NaN                NaN  ...  124.750000   \n",
      "50%      NaN                 NaN                NaN  ...  249.500000   \n",
      "75%      NaN                 NaN                NaN  ...  374.250000   \n",
      "max      NaN                 inf                NaN  ...  499.000000   \n",
      "\n",
      "       lambda_est  m_theory  regret  rho_step  segment_id  sens_delete  \\\n",
      "count         0.0       0.0   500.0       0.0       500.0          0.0   \n",
      "mean          NaN       NaN     0.0       NaN         0.0          NaN   \n",
      "std           NaN       NaN     0.0       NaN         0.0          NaN   \n",
      "min           NaN       NaN     0.0       NaN         0.0          NaN   \n",
      "25%           NaN       NaN     0.0       NaN         0.0          NaN   \n",
      "50%           NaN       NaN     0.0       NaN         0.0          NaN   \n",
      "75%           NaN       NaN     0.0       NaN         0.0          NaN   \n",
      "max           NaN       NaN     0.0       NaN         0.0          NaN   \n",
      "\n",
      "       sigma_step  sigma_step_theory      x_norm  \n",
      "count         0.0                0.0  500.000000  \n",
      "mean          NaN                NaN    4.416784  \n",
      "std           NaN                NaN    0.688767  \n",
      "min           NaN                NaN    2.314139  \n",
      "25%           NaN                NaN    3.896198  \n",
      "50%           NaN                NaN    4.365512  \n",
      "75%           NaN                NaN    4.951774  \n",
      "max           NaN                NaN    6.496877  \n",
      "\n",
      "[8 rows x 25 columns]\n",
      "Value counts for warmup:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/unlearning-research-meta/.venv/lib/python3.11/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/workspaces/unlearning-research-meta/.venv/lib/python3.11/site-packages/numpy/lib/_function_base_impl.py:4671: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C_hat         D_hat       G_hat  N_star_theory  P_T_est  S_scalar  \\\n",
      "count  315.0  3.150000e+02  315.000000          315.0      0.0       0.0   \n",
      "mean     1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "std      0.0  1.111989e-16    0.000000            0.0      NaN       NaN   \n",
      "min      1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "25%      1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "50%      1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "75%      1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "max      1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "\n",
      "              acc  c_hat  capacity_remaining  delta_step_theory  ...  \\\n",
      "count  315.000000  315.0                 0.0                0.0  ...   \n",
      "mean     1.455746    1.0                 NaN                NaN  ...   \n",
      "std      1.102797    0.0                 NaN                NaN  ...   \n",
      "min      0.008724    1.0                 NaN                NaN  ...   \n",
      "25%      0.599033    1.0                 NaN                NaN  ...   \n",
      "50%      1.235127    1.0                 NaN                NaN  ...   \n",
      "75%      2.155150    1.0                 NaN                NaN  ...   \n",
      "max      5.561408    1.0                 NaN                NaN  ...   \n",
      "\n",
      "         event_id  lambda_est  m_theory       regret  rho_step  segment_id  \\\n",
      "count  315.000000         0.0     315.0   315.000000       0.0       315.0   \n",
      "mean   705.000000         NaN       0.0   528.794559       NaN         0.0   \n",
      "std     91.076891         NaN       0.0   307.481726       NaN         0.0   \n",
      "min    548.000000         NaN       0.0     4.724467       NaN         0.0   \n",
      "25%    626.500000         NaN       0.0   263.428318       NaN         0.0   \n",
      "50%    705.000000         NaN       0.0   547.443272       NaN         0.0   \n",
      "75%    783.500000         NaN       0.0   791.842927       NaN         0.0   \n",
      "max    862.000000         NaN       0.0  1049.421200       NaN         0.0   \n",
      "\n",
      "       sens_delete  sigma_step  sigma_step_theory      x_norm  \n",
      "count          0.0         0.0                0.0  315.000000  \n",
      "mean           NaN         NaN                NaN    4.362840  \n",
      "std            NaN         NaN                NaN    0.710819  \n",
      "min            NaN         NaN                NaN    2.262431  \n",
      "25%            NaN         NaN                NaN    3.891133  \n",
      "50%            NaN         NaN                NaN    4.375668  \n",
      "75%            NaN         NaN                NaN    4.842766  \n",
      "max            NaN         NaN                NaN    6.531391  \n",
      "\n",
      "[8 rows x 25 columns]\n",
      "Value counts for insert:\n",
      "       C_hat         D_hat       G_hat  N_star_theory  P_T_est  S_scalar  \\\n",
      "count  292.0  2.920000e+02  292.000000          292.0      0.0       0.0   \n",
      "mean     1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "std      0.0  1.112129e-16    0.000000            0.0      NaN       NaN   \n",
      "min      1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "25%      1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "50%      1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "75%      1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "max      1.0  5.213894e-01   16.420728          815.0      NaN       NaN   \n",
      "\n",
      "                acc  c_hat  capacity_remaining  delta_step_theory  ...  \\\n",
      "count  2.920000e+02  292.0                 0.0       2.920000e+02  ...   \n",
      "mean   1.072149e+07    1.0                 NaN       3.436426e-08  ...   \n",
      "std    9.822036e+06    0.0                 NaN       0.000000e+00  ...   \n",
      "min    1.626889e+00    1.0                 NaN       3.436426e-08  ...   \n",
      "25%    3.425384e+06    1.0                 NaN       3.436426e-08  ...   \n",
      "50%    7.399950e+06    1.0                 NaN       3.436426e-08  ...   \n",
      "75%    1.526315e+07    1.0                 NaN       3.436426e-08  ...   \n",
      "max    4.781880e+07    1.0                 NaN       3.436426e-08  ...   \n",
      "\n",
      "          event_id  lambda_est  m_theory        regret  rho_step  segment_id  \\\n",
      "count   292.000000         0.0     292.0  2.920000e+02       0.0       292.0   \n",
      "mean   1153.000000         NaN     291.0  2.019227e+16       NaN         0.0   \n",
      "std     168.874707         NaN       0.0  1.961690e+16       NaN         0.0   \n",
      "min     862.000000         NaN     291.0  1.052068e+03       NaN         0.0   \n",
      "25%    1007.500000         NaN     291.0  2.912291e+15       NaN         0.0   \n",
      "50%    1153.000000         NaN     291.0  1.224211e+16       NaN         0.0   \n",
      "75%    1298.500000         NaN     291.0  3.687563e+16       NaN         0.0   \n",
      "max    1444.000000         NaN     291.0  6.163899e+16       NaN         0.0   \n",
      "\n",
      "       sens_delete  sigma_step  sigma_step_theory      x_norm  \n",
      "count          0.0         0.0       2.920000e+02  292.000000  \n",
      "mean           NaN         NaN       2.819630e+05    4.384504  \n",
      "std            NaN         NaN       5.830759e-11    0.754324  \n",
      "min            NaN         NaN       2.819630e+05    2.041483  \n",
      "25%            NaN         NaN       2.819630e+05    3.798479  \n",
      "50%            NaN         NaN       2.819630e+05    4.374336  \n",
      "75%            NaN         NaN       2.819630e+05    4.878606  \n",
      "max            NaN         NaN       2.819630e+05    6.901854  \n",
      "\n",
      "[8 rows x 25 columns]\n",
      "Value counts for delete:\n",
      "       C_hat         D_hat       G_hat  N_star_theory  P_T_est  S_scalar  acc  \\\n",
      "count  291.0  2.910000e+02  291.000000          291.0      0.0       0.0  0.0   \n",
      "mean     1.0  5.213894e-01   16.420728          815.0      NaN       NaN  NaN   \n",
      "std      0.0  1.112136e-16    0.000000            0.0      NaN       NaN  NaN   \n",
      "min      1.0  5.213894e-01   16.420728          815.0      NaN       NaN  NaN   \n",
      "25%      1.0  5.213894e-01   16.420728          815.0      NaN       NaN  NaN   \n",
      "50%      1.0  5.213894e-01   16.420728          815.0      NaN       NaN  NaN   \n",
      "75%      1.0  5.213894e-01   16.420728          815.0      NaN       NaN  NaN   \n",
      "max      1.0  5.213894e-01   16.420728          815.0      NaN       NaN  NaN   \n",
      "\n",
      "       c_hat  capacity_remaining  delta_step_theory  ...     event_id  \\\n",
      "count  291.0                 0.0       2.910000e+02  ...   291.000000   \n",
      "mean     1.0                 NaN       3.436426e-08  ...  1153.000000   \n",
      "std      0.0                 NaN       0.000000e+00  ...   168.297356   \n",
      "min      1.0                 NaN       3.436426e-08  ...   863.000000   \n",
      "25%      1.0                 NaN       3.436426e-08  ...  1008.000000   \n",
      "50%      1.0                 NaN       3.436426e-08  ...  1153.000000   \n",
      "75%      1.0                 NaN       3.436426e-08  ...  1298.000000   \n",
      "max      1.0                 NaN       3.436426e-08  ...  1443.000000   \n",
      "\n",
      "       lambda_est  m_theory        regret  rho_step  segment_id  sens_delete  \\\n",
      "count         0.0     291.0  2.910000e+02       0.0       291.0          0.0   \n",
      "mean          NaN     291.0  2.004984e+16       NaN         0.0          NaN   \n",
      "std           NaN       0.0  1.949886e+16       NaN         0.0          NaN   \n",
      "min           NaN     291.0  1.052068e+03       NaN         0.0          NaN   \n",
      "25%           NaN     291.0  2.903722e+15       NaN         0.0          NaN   \n",
      "50%           NaN     291.0  1.218151e+16       NaN         0.0          NaN   \n",
      "75%           NaN     291.0  3.677412e+16       NaN         0.0          NaN   \n",
      "max           NaN     291.0  6.163807e+16       NaN         0.0          NaN   \n",
      "\n",
      "       sigma_step  sigma_step_theory      x_norm  \n",
      "count         0.0       2.910000e+02  291.000000  \n",
      "mean          NaN       2.819630e+05    4.311382  \n",
      "std           NaN       5.830793e-11    0.683112  \n",
      "min           NaN       2.819630e+05    2.653250  \n",
      "25%           NaN       2.819630e+05    3.806960  \n",
      "50%           NaN       2.819630e+05    4.305624  \n",
      "75%           NaN       2.819630e+05    4.727809  \n",
      "max           NaN       2.819630e+05    6.728326  \n",
      "\n",
      "[8 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# print value counts for each event type\n",
    "for event_type, df in event_dfs.items():\n",
    "    print(f\"Value counts for {event_type}:\")\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf73f8a",
   "metadata": {},
   "source": [
    "The code performs a grid search over the experiment parameters. For each seed,\n",
    "1. **(Calibration.)** a `Calibrator` object draws a small sample of the data stream to estimate stream-attributes like the Lipschitz constant $L$, the upper and lower bound of the Hessian eigenvalues $C, C$, and the resulting sample complexity required to meet predefined accuracy goals.\n",
    "2. **(Warmup.)** the model is trained on a stream of samples until it reaches sample complexity. This sets the model up for success when we test deletions.\n",
    "3. **(Workload.)** a stream of interleaved insertions and deletions is passed to the model. It's expected to service the requests in the order they're given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295985d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot describe a DataFrame without columns",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m summary_statistics = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m summary_statistics.columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/.venv/lib/python3.11/site-packages/pandas/core/generic.py:11995\u001b[39m, in \u001b[36mNDFrame.describe\u001b[39m\u001b[34m(self, percentiles, include, exclude)\u001b[39m\n\u001b[32m  11753\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m  11754\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdescribe\u001b[39m(\n\u001b[32m  11755\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  11758\u001b[39m     exclude=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  11759\u001b[39m ) -> Self:\n\u001b[32m  11760\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m  11761\u001b[39m \u001b[33;03m    Generate descriptive statistics.\u001b[39;00m\n\u001b[32m  11762\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m  11993\u001b[39m \u001b[33;03m    max            NaN      3.0\u001b[39;00m\n\u001b[32m  11994\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m11995\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdescribe_ndframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  11996\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  11997\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  11998\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  11999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpercentiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12000\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mdescribe\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/.venv/lib/python3.11/site-packages/pandas/core/methods/describe.py:91\u001b[39m, in \u001b[36mdescribe_ndframe\u001b[39m\u001b[34m(obj, include, exclude, percentiles)\u001b[39m\n\u001b[32m     87\u001b[39m     describer = SeriesDescriber(\n\u001b[32m     88\u001b[39m         obj=cast(\u001b[33m\"\u001b[39m\u001b[33mSeries\u001b[39m\u001b[33m\"\u001b[39m, obj),\n\u001b[32m     89\u001b[39m     )\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     describer = \u001b[43mDataFrameDescriber\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDataFrame\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m result = describer.describe(percentiles=percentiles)\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(NDFrameT, result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/.venv/lib/python3.11/site-packages/pandas/core/methods/describe.py:162\u001b[39m, in \u001b[36mDataFrameDescriber.__init__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28mself\u001b[39m.exclude = exclude\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m obj.columns.size == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot describe a DataFrame without columns\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    164\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(obj)\n",
      "\u001b[31mValueError\u001b[39m: Cannot describe a DataFrame without columns"
     ]
    }
   ],
   "source": [
    "summary_statistics = data.describe()\n",
    "summary_statistics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6715a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['calibrate' 'warmup' 'insert' 'delete']\n",
      "event_type\n",
      "warmup       169493\n",
      "calibrate      2500\n",
      "insert         1932\n",
      "delete         1927\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get the individual event types\n",
    "print(data[\"event_type\"].unique())\n",
    "print(data[\"event_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc11c680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_hat</th>\n",
       "      <th>D_hat</th>\n",
       "      <th>G_hat</th>\n",
       "      <th>N_star_theory</th>\n",
       "      <th>acc</th>\n",
       "      <th>c_hat</th>\n",
       "      <th>capacity_remaining</th>\n",
       "      <th>delta_step_theory</th>\n",
       "      <th>delta_total</th>\n",
       "      <th>eps_spent</th>\n",
       "      <th>...</th>\n",
       "      <th>sigma_step_theory</th>\n",
       "      <th>gamma_learning</th>\n",
       "      <th>gamma_privacy</th>\n",
       "      <th>quantile</th>\n",
       "      <th>deletion_ratio</th>\n",
       "      <th>accountant_type</th>\n",
       "      <th>privacy_budget</th>\n",
       "      <th>seed</th>\n",
       "      <th>data_stream_type</th>\n",
       "      <th>algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.995444e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.302350e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.028844e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.397093e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.504764e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175847</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.710798</td>\n",
       "      <td>4.605077</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>1.305034e+27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426534e-08</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.997147</td>\n",
       "      <td>...</td>\n",
       "      <td>195235.982215</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175848</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.710798</td>\n",
       "      <td>4.605077</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426534e-08</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>...</td>\n",
       "      <td>195235.982215</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175849</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.710798</td>\n",
       "      <td>4.605077</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>9.006921e+25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426534e-08</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>...</td>\n",
       "      <td>195235.982215</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175850</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.710798</td>\n",
       "      <td>4.605077</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426534e-08</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>195235.982215</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175851</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.710798</td>\n",
       "      <td>4.605077</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>7.102584e+26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426534e-08</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>195235.982215</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175852 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        C_hat     D_hat     G_hat  N_star_theory           acc  c_hat  \\\n",
       "0         NaN       NaN       NaN            NaN  1.995444e+00    NaN   \n",
       "1         NaN       NaN       NaN            NaN  2.302350e+00    NaN   \n",
       "2         NaN       NaN       NaN            NaN  5.028844e+00    NaN   \n",
       "3         NaN       NaN       NaN            NaN  1.397093e+01    NaN   \n",
       "4         NaN       NaN       NaN            NaN  8.504764e+00    NaN   \n",
       "...       ...       ...       ...            ...           ...    ...   \n",
       "175847    1.0  4.710798  4.605077         1883.0  1.305034e+27    1.0   \n",
       "175848    1.0  4.710798  4.605077         1883.0           NaN    1.0   \n",
       "175849    1.0  4.710798  4.605077         1883.0  9.006921e+25    1.0   \n",
       "175850    1.0  4.710798  4.605077         1883.0           NaN    1.0   \n",
       "175851    1.0  4.710798  4.605077         1883.0  7.102584e+26    1.0   \n",
       "\n",
       "        capacity_remaining  delta_step_theory  delta_total  eps_spent  ...  \\\n",
       "0                      inf                NaN          NaN   0.000000  ...   \n",
       "1                      inf                NaN          NaN   0.000000  ...   \n",
       "2                      inf                NaN          NaN   0.000000  ...   \n",
       "3                      inf                NaN          NaN   0.000000  ...   \n",
       "4                      inf                NaN          NaN   0.000000  ...   \n",
       "...                    ...                ...          ...        ...  ...   \n",
       "175847                 NaN       1.426534e-08      0.00001   0.997147  ...   \n",
       "175848                 NaN       1.426534e-08      0.00001   0.998573  ...   \n",
       "175849                 NaN       1.426534e-08      0.00001   0.998573  ...   \n",
       "175850                 NaN       1.426534e-08      0.00001   1.000000  ...   \n",
       "175851                 NaN       1.426534e-08      0.00001   1.000000  ...   \n",
       "\n",
       "        sigma_step_theory  gamma_learning gamma_privacy  quantile  \\\n",
       "0                     NaN             0.5           0.5      0.90   \n",
       "1                     NaN             0.5           0.5      0.90   \n",
       "2                     NaN             0.5           0.5      0.90   \n",
       "3                     NaN             0.5           0.5      0.90   \n",
       "4                     NaN             0.5           0.5      0.90   \n",
       "...                   ...             ...           ...       ...   \n",
       "175847      195235.982215             0.5           0.5      0.90   \n",
       "175848      195235.982215             0.5           0.5      0.90   \n",
       "175849      195235.982215             0.5           0.5      0.90   \n",
       "175850      195235.982215             0.5           0.5      0.90   \n",
       "175851      195235.982215             0.5           0.5      0.90   \n",
       "\n",
       "       deletion_ratio  accountant_type  privacy_budget seed data_stream_type  \\\n",
       "0                   1           legacy             1.0    5        synthetic   \n",
       "1                   1           legacy             1.0    5        synthetic   \n",
       "2                   1           legacy             1.0    5        synthetic   \n",
       "3                   1           legacy             1.0    5        synthetic   \n",
       "4                   1           legacy             1.0    5        synthetic   \n",
       "...               ...              ...             ...  ...              ...   \n",
       "175847              1           legacy             1.0    0        synthetic   \n",
       "175848              1           legacy             1.0    0        synthetic   \n",
       "175849              1           legacy             1.0    0        synthetic   \n",
       "175850              1           legacy             1.0    0        synthetic   \n",
       "175851              1           legacy             1.0    0        synthetic   \n",
       "\n",
       "         algorithm  \n",
       "0       memorypair  \n",
       "1       memorypair  \n",
       "2       memorypair  \n",
       "3       memorypair  \n",
       "4       memorypair  \n",
       "...            ...  \n",
       "175847  memorypair  \n",
       "175848  memorypair  \n",
       "175849  memorypair  \n",
       "175850  memorypair  \n",
       "175851  memorypair  \n",
       "\n",
       "[175852 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf63d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_level_data = data.loc[data[\"event_type\"].isnull()]\n",
    "event_level_data = data.loc[~data[\"event_type\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd49f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_hat</th>\n",
       "      <th>D_hat</th>\n",
       "      <th>G_hat</th>\n",
       "      <th>N_star_theory</th>\n",
       "      <th>acc</th>\n",
       "      <th>c_hat</th>\n",
       "      <th>capacity_remaining</th>\n",
       "      <th>delta_step_theory</th>\n",
       "      <th>delta_total</th>\n",
       "      <th>eps_spent</th>\n",
       "      <th>...</th>\n",
       "      <th>sigma_step_theory</th>\n",
       "      <th>gamma_learning</th>\n",
       "      <th>gamma_privacy</th>\n",
       "      <th>quantile</th>\n",
       "      <th>deletion_ratio</th>\n",
       "      <th>accountant_type</th>\n",
       "      <th>privacy_budget</th>\n",
       "      <th>seed</th>\n",
       "      <th>data_stream_type</th>\n",
       "      <th>algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.995444e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.302350e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.028844e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.397093e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.504764e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175847</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.710798</td>\n",
       "      <td>4.605077</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>1.305034e+27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426534e-08</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.997147</td>\n",
       "      <td>...</td>\n",
       "      <td>195235.982215</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175848</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.710798</td>\n",
       "      <td>4.605077</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426534e-08</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>...</td>\n",
       "      <td>195235.982215</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175849</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.710798</td>\n",
       "      <td>4.605077</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>9.006921e+25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426534e-08</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>...</td>\n",
       "      <td>195235.982215</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175850</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.710798</td>\n",
       "      <td>4.605077</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426534e-08</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>195235.982215</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175851</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.710798</td>\n",
       "      <td>4.605077</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>7.102584e+26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426534e-08</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>195235.982215</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>legacy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>memorypair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175852 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        C_hat     D_hat     G_hat  N_star_theory           acc  c_hat  \\\n",
       "0         NaN       NaN       NaN            NaN  1.995444e+00    NaN   \n",
       "1         NaN       NaN       NaN            NaN  2.302350e+00    NaN   \n",
       "2         NaN       NaN       NaN            NaN  5.028844e+00    NaN   \n",
       "3         NaN       NaN       NaN            NaN  1.397093e+01    NaN   \n",
       "4         NaN       NaN       NaN            NaN  8.504764e+00    NaN   \n",
       "...       ...       ...       ...            ...           ...    ...   \n",
       "175847    1.0  4.710798  4.605077         1883.0  1.305034e+27    1.0   \n",
       "175848    1.0  4.710798  4.605077         1883.0           NaN    1.0   \n",
       "175849    1.0  4.710798  4.605077         1883.0  9.006921e+25    1.0   \n",
       "175850    1.0  4.710798  4.605077         1883.0           NaN    1.0   \n",
       "175851    1.0  4.710798  4.605077         1883.0  7.102584e+26    1.0   \n",
       "\n",
       "        capacity_remaining  delta_step_theory  delta_total  eps_spent  ...  \\\n",
       "0                      inf                NaN          NaN   0.000000  ...   \n",
       "1                      inf                NaN          NaN   0.000000  ...   \n",
       "2                      inf                NaN          NaN   0.000000  ...   \n",
       "3                      inf                NaN          NaN   0.000000  ...   \n",
       "4                      inf                NaN          NaN   0.000000  ...   \n",
       "...                    ...                ...          ...        ...  ...   \n",
       "175847                 NaN       1.426534e-08      0.00001   0.997147  ...   \n",
       "175848                 NaN       1.426534e-08      0.00001   0.998573  ...   \n",
       "175849                 NaN       1.426534e-08      0.00001   0.998573  ...   \n",
       "175850                 NaN       1.426534e-08      0.00001   1.000000  ...   \n",
       "175851                 NaN       1.426534e-08      0.00001   1.000000  ...   \n",
       "\n",
       "        sigma_step_theory  gamma_learning gamma_privacy  quantile  \\\n",
       "0                     NaN             0.5           0.5      0.90   \n",
       "1                     NaN             0.5           0.5      0.90   \n",
       "2                     NaN             0.5           0.5      0.90   \n",
       "3                     NaN             0.5           0.5      0.90   \n",
       "4                     NaN             0.5           0.5      0.90   \n",
       "...                   ...             ...           ...       ...   \n",
       "175847      195235.982215             0.5           0.5      0.90   \n",
       "175848      195235.982215             0.5           0.5      0.90   \n",
       "175849      195235.982215             0.5           0.5      0.90   \n",
       "175850      195235.982215             0.5           0.5      0.90   \n",
       "175851      195235.982215             0.5           0.5      0.90   \n",
       "\n",
       "       deletion_ratio  accountant_type  privacy_budget seed data_stream_type  \\\n",
       "0                   1           legacy             1.0    5        synthetic   \n",
       "1                   1           legacy             1.0    5        synthetic   \n",
       "2                   1           legacy             1.0    5        synthetic   \n",
       "3                   1           legacy             1.0    5        synthetic   \n",
       "4                   1           legacy             1.0    5        synthetic   \n",
       "...               ...              ...             ...  ...              ...   \n",
       "175847              1           legacy             1.0    0        synthetic   \n",
       "175848              1           legacy             1.0    0        synthetic   \n",
       "175849              1           legacy             1.0    0        synthetic   \n",
       "175850              1           legacy             1.0    0        synthetic   \n",
       "175851              1           legacy             1.0    0        synthetic   \n",
       "\n",
       "         algorithm  \n",
       "0       memorypair  \n",
       "1       memorypair  \n",
       "2       memorypair  \n",
       "3       memorypair  \n",
       "4       memorypair  \n",
       "...            ...  \n",
       "175847  memorypair  \n",
       "175848  memorypair  \n",
       "175849  memorypair  \n",
       "175850  memorypair  \n",
       "175851  memorypair  \n",
       "\n",
       "[175852 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_level_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70084b3",
   "metadata": {},
   "source": [
    "### What does this data mean?\n",
    "\n",
    "The data we get from the experiment is incredibly granular. This is good because we can isolate the impact of different operations on the regret. A list of the parameters is included below:\n",
    "\n",
    "`Data Stream Attributes`\n",
    "- $q$ is the quantile used for selecting the parameter estimates so we don't accidentally pull a high-ass parameter estimate\n",
    "- $\\widehat{C}$ is the upper bound on the Hessian eigenvalues\n",
    "- $\\widehat{C}$ is the lower bound on the Hessian eigenvalues\n",
    "- $\\widehat{D}$ is the upper bound of the diameter of the ellipsoid\n",
    "- $\\widehat{G}$ is the Lipschitz constant of the function, representing how much the output of the function changes as the inputs change\n",
    "- $N^{\\star}_{theory}$ is the theoretical sample complexity to reach the specified amount of average-regret\n",
    "\n",
    "`Workload Parameters`\n",
    "- $k$ is the number of insertions per delete operation\n",
    "- $m_{emp}$ is the empirical deletion capacity of the seed\n",
    "\n",
    "`Privacy Parameters`\n",
    "- $\\delta_{total}$ and $\\varepsilon_{total}$ are the total $(\\varepsilon,\\delta)$ budget given the the accountant\n",
    "- $\\delta_{step}$ and $\\varepsilon_{step}$ are the amount of privacy \"spent\" per deletion\n",
    "\n",
    "\n",
    "`Event-Level Attributes`\n",
    "- $event$ is the zero-based index of the operation within the seed run\n",
    "- $avg\\_regret\\_empirical$ is the mean per-operation regret for the stream of events up to this point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e2ab42",
   "metadata": {},
   "source": [
    "## Theoretical Sample Complexities\n",
    "\n",
    "We can calculate theoretical sample complexities using the data we get from calibration. \n",
    "\n",
    "The formula for the sample complexity is based entirely on the attributes of our data stream and its spread: $G$, $D$, and $\\sqrt{cC}$ and so the estimates from our calibration period actually mean a lot. A large estimate for Lipschitz constant, or the bounds of our Hessian eigenvalues means we'll have an artificially inflated Sample Complexity.\n",
    "\n",
    "$$\n",
    "S = [\\frac{GD\\sqrt{Cc}}{\\gamma_{learn}}]^{2}\n",
    "$$\n",
    "\n",
    "It's also worth noting that the sample complexity is already quite conservative because of the method used for accouting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad19ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>N_star_theory</th>\n",
       "      <th>C_hat</th>\n",
       "      <th>c_hat</th>\n",
       "      <th>D_hat</th>\n",
       "      <th>G_hat</th>\n",
       "      <th>gamma_learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [seed, N_star_theory, C_hat, c_hat, D_hat, G_hat, gamma_learning]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_complexity_calculations = seed_level_data[[\"seed\", \"N_star_theory\", \"C_hat\", \"c_hat\", \"D_hat\", \"G_hat\", \"gamma_learning\"]]\n",
    "sample_complexity_calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c1e01",
   "metadata": {},
   "source": [
    "### Interpreting $\\gamma$ Parameters\n",
    "\n",
    "**Question:** What is the interpretation of $\\gamma_{learn}$ and how is it used to calculate sample complexity and deletion capacity?\n",
    "\n",
    "**Answer:** If $\\gamma_{learn}$ is the amount of slack given to the learner, then a $\\gamma_{learn}$ of `0.5` is really inflating my sample complexity by 4. Consider a larger $\\gamma_{learn}$ for the first round of experiments so that you don't blow up your sample complexity too early.\n",
    "\n",
    "The large sample complexities can also be an issue because our `max_events` parameter is set to 100000. So if the sample complexity is any larger than that, then the learner wouldn't even be able to unlearn a single point.\n",
    "\n",
    "**Question:** Okay, so we have two parameters $\\gamma_{learn}$ and $\\gamma_{private}$, why do we need them both? What's the difference between the learning parameter or the private parameter?\n",
    "\n",
    "**Answer:** They were separated because we need two separate slack parameters. One is used to bound the average regret during the learning period, and the second is used to bound the average regret when processing the workload.\n",
    "\n",
    "### Effects of Limited Convexity\n",
    "\n",
    "If the loss function is only weakly convex, then the experiment would end before the sample complexity is reached, and so even doing a single insertion would be a waste of time. I'm increasing the maximum number of events to allow for more of the experiments to reach this stage.\n",
    "\n",
    "**Note:** a suggestion would be to replace the two gamma parameters with a single $\\alpha$ that's used to split the amount of slack given to deletions versus insertions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c813ff",
   "metadata": {},
   "source": [
    "## Theoretical Deletion Capacities \n",
    "\n",
    "The $\\gamma_{priv}$ is also used to calculate deletion capacity. The quantifies the amount of cumulative regret you're willing to pay for all future deletions. It's used to calculate the upper bound on deletion capacity.\n",
    "\n",
    "$$\n",
    "m \\leq \\gamma_{priv} \\times \\frac{N^{\\star}}{GD + \\sigma\\sqrt{2N^{*}\\ln{\\frac{1}{\\delta_{step}}}}}\n",
    "$$\n",
    "\n",
    "The deletion capacity is only determined once the warmup has completed. We use the calibration statistics and the results from the warmup to calculate the theoretical deletion capacity for the experiment. This is the maximum number of deletions served (although many seeds never reach that point) and is used to calibrate the noise in the standard odometer.\n",
    "\n",
    "For some reason, we're not getting the $m_{theory}$ that we need to actually run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e21d69",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['m_emp', 'gamma_priv'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m deletion_capacity_data = \u001b[43mseed_level_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mm_theory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mm_emp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgamma_priv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mG_hat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mD_hat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mN_star_theory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msigma_step_theory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      2\u001b[39m deletion_capacity_data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/unlearning-research-meta/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['m_emp', 'gamma_priv'] not in index\""
     ]
    }
   ],
   "source": [
    "deletion_capacity_data = seed_level_data[[\"seed\", \"m_theory\",\"m_emp\", \"gamma_priv\", \"G_hat\", \"D_hat\", \"N_star_theory\", \"sigma_step_theory\"]]\n",
    "deletion_capacity_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65029edd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
